{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langgraph langchain-openai pydantic httpx tenacity psutil\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RUGv2bqZo2Af",
        "outputId": "585eea53-7238-4006-9385-c638593440f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.34-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.9)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (8.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (5.9.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.28)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Downloading langchain_core-0.3.77-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.108.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Downloading langgraph-0.6.8-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.34-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.77-py3-none-any.whl (449 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m449.5/449.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.76\n",
            "    Uninstalling langchain-core-0.3.76:\n",
            "      Successfully uninstalled langchain-core-0.3.76\n",
            "Successfully installed langchain-core-0.3.77 langchain-openai-0.3.34 langgraph-0.6.8 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 ormsgpack-1.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain_core"
                ]
              },
              "id": "53a50cc0827b4378903706faa656e4ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SAac_X7pdaM",
        "outputId": "20831fd3-2050-4128-e109-516fc38c59b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Complete CV Evaluation System using LangGraph - FIXED VERSION\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# IMPORTS\n",
        "# ============================================================================\n",
        "from typing import TypedDict, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langgraph.graph import StateGraph, END\n",
        "import json\n",
        "import time\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "import httpx\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import re\n",
        "\n",
        "\n",
        "model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def llm_call(prompt, max_tokens=1024, temperature=0.3):\n",
        "    \"\"\"Call LLM with better parameters for JSON generation\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=temperature,\n",
        "        top_p=0.95,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return result\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MODELS & TYPE DEFINITIONS\n",
        "# ============================================================================\n",
        "\n",
        "class Screening(BaseModel):\n",
        "    \"\"\"Model for CV screening results.\"\"\"\n",
        "    score: bool = Field(\n",
        "        ...,\n",
        "        description=\"Return True if the candidate's CV matches the job requirements, otherwise return False.\"\n",
        "    )\n",
        "    reasoning: str = Field(\n",
        "        default=\"\",\n",
        "        description=\"Brief explanation of the screening decision.\"\n",
        "    )\n",
        "    matched_skills: list[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"List of skills from CV that match job requirements.\"\n",
        "    )\n",
        "    missing_requirements: list[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"List of requirements that are missing from the CV.\"\n",
        "    )\n",
        "\n",
        "\n",
        "class QuestionSet(BaseModel):\n",
        "    \"\"\"Model for set of interview questions.\"\"\"\n",
        "    questions: list[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of 20 interview questions based on CV and job requirements\"\n",
        "    )\n",
        "\n",
        "\n",
        "class IdeaEvaluationState(TypedDict, total=False):\n",
        "    \"\"\"State dictionary for CV evaluation workflow.\"\"\"\n",
        "    cv: str\n",
        "    required_cv: str\n",
        "    screening: Optional[dict]\n",
        "    candidate_email: Optional[str]\n",
        "    candidate_name: Optional[str]\n",
        "    company_name: Optional[str]\n",
        "    email_sent: Optional[bool]\n",
        "    questions: Optional[dict]\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# IMPROVED JSON EXTRACTION\n",
        "# ============================================================================\n",
        "\n",
        "def extract_json(text: str) -> str:\n",
        "    \"\"\"Extract JSON object from LLM response with better error handling\"\"\"\n",
        "    # Remove the prompt echo if present\n",
        "    if \"Human:\" in text:\n",
        "        text = text.split(\"Human:\")[-1]\n",
        "\n",
        "    # Try to find JSON object between curly braces\n",
        "    json_pattern = r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}'\n",
        "    matches = re.findall(json_pattern, text, re.DOTALL)\n",
        "\n",
        "    for match in matches:\n",
        "        try:\n",
        "            # Try to parse it\n",
        "            obj = json.loads(match)\n",
        "            # Check if it has the required 'score' field\n",
        "            if 'score' in obj:\n",
        "                return json.dumps(obj)\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "    # If no valid JSON found, try to extract key-value pairs manually\n",
        "    try:\n",
        "        # Look for score\n",
        "        score_match = re.search(r'\"score\"\\s*:\\s*(true|false)', text, re.IGNORECASE)\n",
        "        score = score_match.group(1).lower() == 'true' if score_match else False\n",
        "\n",
        "        # Look for reasoning\n",
        "        reasoning_match = re.search(r'\"reasoning\"\\s*:\\s*\"([^\"]*)\"', text, re.DOTALL)\n",
        "        reasoning = reasoning_match.group(1) if reasoning_match else \"\"\n",
        "\n",
        "        # Look for matched_skills array\n",
        "        skills_match = re.search(r'\"matched_skills\"\\s*:\\s*\\[(.*?)\\]', text, re.DOTALL)\n",
        "        matched_skills = []\n",
        "        if skills_match:\n",
        "            skills_text = skills_match.group(1)\n",
        "            matched_skills = [s.strip().strip('\"') for s in skills_text.split(',') if s.strip()]\n",
        "\n",
        "        # Look for missing_requirements array\n",
        "        missing_match = re.search(r'\"missing_requirements\"\\s*:\\s*\\[(.*?)\\]', text, re.DOTALL)\n",
        "        missing_requirements = []\n",
        "        if missing_match:\n",
        "            missing_text = missing_match.group(1)\n",
        "            missing_requirements = [s.strip().strip('\"') for s in missing_text.split(',') if s.strip()]\n",
        "\n",
        "        # Construct valid JSON\n",
        "        result = {\n",
        "            \"score\": score,\n",
        "            \"reasoning\": reasoning,\n",
        "            \"matched_skills\": matched_skills,\n",
        "            \"missing_requirements\": missing_requirements\n",
        "        }\n",
        "        return json.dumps(result)\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ JSON extraction failed: {e}\")\n",
        "        # Return minimal valid JSON as last resort\n",
        "        return json.dumps({\n",
        "            \"score\": False,\n",
        "            \"reasoning\": \"Failed to parse LLM response\",\n",
        "            \"matched_skills\": [],\n",
        "            \"missing_requirements\": [\"Unable to evaluate\"]\n",
        "        })\n",
        "\n",
        "\n",
        "def prompt_from(text: str):\n",
        "    \"\"\"Helper function to create a ChatPromptTemplate from text.\"\"\"\n",
        "    return ChatPromptTemplate.from_template(text)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SIMPLIFIED PROMPTS\n",
        "# ============================================================================\n",
        "\n",
        "prompt_screening_text = \"\"\"You are an HR recruiter. Analyze this CV against job requirements.\n",
        "\n",
        "Job Requirements:\n",
        "{required_cv}\n",
        "\n",
        "Candidate CV:\n",
        "{cv}\n",
        "\n",
        "Respond with ONLY a JSON object (no markdown, no explanation):\n",
        "{{\n",
        "  \"score\": true or false,\n",
        "  \"reasoning\": \"brief explanation\",\n",
        "  \"matched_skills\": [\"skill1\", \"skill2\"],\n",
        "  \"missing_requirements\": [\"requirement1\", \"requirement2\"]\n",
        "}}\n",
        "\n",
        "Set score=true if candidate meets core requirements, false otherwise.\"\"\"\n",
        "\n",
        "prompt_screening = prompt_from(prompt_screening_text)\n",
        "\n",
        "json_screening = JsonOutputParser(pydantic_object=Screening)\n",
        "\n",
        "prompt_questions_text = \"\"\"Generate 20 interview questions for this candidate.\n",
        "\n",
        "Job Requirements:\n",
        "{required_cv}\n",
        "\n",
        "Candidate CV:\n",
        "{cv}\n",
        "\n",
        "Respond with ONLY a JSON object:\n",
        "{{\n",
        "  \"questions\": [\"question1\", \"question2\", ...]\n",
        "}}\n",
        "\n",
        "Include 10 technical, 5 experience-based, and 5 problem-solving questions.\"\"\"\n",
        "\n",
        "prompt_questions = prompt_from(prompt_questions_text)\n",
        "json_questions = JsonOutputParser(pydantic_object=QuestionSet)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# GRAPH NODES\n",
        "# ============================================================================\n",
        "\n",
        "@retry(\n",
        "    stop=stop_after_attempt(3),\n",
        "    wait=wait_exponential(multiplier=1, min=2, max=10),\n",
        "    retry=retry_if_exception_type((httpx.RemoteProtocolError, httpx.ReadTimeout, ConnectionError))\n",
        ")\n",
        "def run_chain(prompt, parser, state: IdeaEvaluationState, key: str) -> IdeaEvaluationState:\n",
        "    try:\n",
        "        # Format prompt\n",
        "        prompt_text = prompt.format(\n",
        "            cv=state[\"cv\"],\n",
        "            required_cv=state[\"required_cv\"]\n",
        "        )\n",
        "\n",
        "        print(f\"\\nğŸ“¤ Sending prompt to LLM...\")\n",
        "        response = llm_call(prompt_text, max_tokens=1024, temperature=0.3)\n",
        "        print(f\"\\nğŸ” Raw LLM response:\\n{response[:500]}...\")\n",
        "\n",
        "        # Extract JSON\n",
        "        clean_response = extract_json(response)\n",
        "        print(f\"\\nâœ¨ Extracted JSON:\\n{clean_response}\")\n",
        "\n",
        "        # Parse JSON\n",
        "        try:\n",
        "            result = json.loads(clean_response)\n",
        "            # Validate it has required fields\n",
        "            if key == \"screening\" and \"score\" not in result:\n",
        "                raise ValueError(\"Missing 'score' field in response\")\n",
        "\n",
        "            new_state = dict(state)\n",
        "            new_state[key] = result\n",
        "            return new_state\n",
        "\n",
        "        except (json.JSONDecodeError, ValueError) as e:\n",
        "            print(f\"âš ï¸ JSON parsing error: {e}\")\n",
        "            raise\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Attempt failed: {str(e)[:100]}...\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def screening_agent(state: IdeaEvaluationState) -> IdeaEvaluationState:\n",
        "    \"\"\"Agent node for CV screening with error handling.\"\"\"\n",
        "    print(\"\\nğŸ” Starting CV Screening...\")\n",
        "    try:\n",
        "        return run_chain(prompt_screening, json_screening, state, \"screening\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Screening agent failed after retries: {e}\")\n",
        "        new_state = dict(state)\n",
        "        new_state[\"screening\"] = {\n",
        "            \"score\": False,\n",
        "            \"reasoning\": f\"Error during evaluation: {str(e)[:200]}\",\n",
        "            \"matched_skills\": [],\n",
        "            \"missing_requirements\": [\"Unable to complete evaluation due to technical error\"]\n",
        "        }\n",
        "        return new_state\n",
        "\n",
        "\n",
        "def email_agent(state: IdeaEvaluationState) -> IdeaEvaluationState:\n",
        "    \"\"\"Email notification agent (placeholder).\"\"\"\n",
        "    print(\"\\nğŸ“§ Email notification step...\")\n",
        "    screening = state.get(\"screening\", {})\n",
        "    score = screening.get(\"score\", False)\n",
        "\n",
        "    if score:\n",
        "        print(\"âœ… Candidate ACCEPTED - Would send acceptance email\")\n",
        "    else:\n",
        "        print(\"âŒ Candidate REJECTED - Would send rejection email\")\n",
        "\n",
        "    new_state = dict(state)\n",
        "    new_state[\"email_sent\"] = True\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def should_continue_to_interview(state: IdeaEvaluationState) -> str:\n",
        "    \"\"\"Route after email - continue to interview if accepted.\"\"\"\n",
        "    screening = state.get(\"screening\", {})\n",
        "    if screening.get(\"score\", False):\n",
        "        return \"question_generator_agent\"\n",
        "    else:\n",
        "        return END\n",
        "\n",
        "\n",
        "def question_generator_agent(state: IdeaEvaluationState) -> IdeaEvaluationState:\n",
        "    \"\"\"Question Generation Agent.\"\"\"\n",
        "    print(\"\\nğŸ“ Generating interview questions...\")\n",
        "\n",
        "    if not state.get(\"screening\", {}).get(\"score\", False):\n",
        "        print(\"â­ï¸ Skipping question generation (candidate rejected)\")\n",
        "        return state\n",
        "\n",
        "    try:\n",
        "        result = run_chain(prompt_questions, json_questions, state, \"questions\")\n",
        "        questions = result.get(\"questions\", {}).get(\"questions\", [])\n",
        "        print(f\"âœ… Generated {len(questions)} questions\")\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Question generation failed: {e}\")\n",
        "        return state\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# GRAPH BUILDING\n",
        "# ============================================================================\n",
        "\n",
        "def build_graph():\n",
        "    \"\"\"Factory function to create a new graph instance.\"\"\"\n",
        "    workflow = StateGraph(IdeaEvaluationState)\n",
        "\n",
        "    workflow.add_node(\"screening_agent\", screening_agent)\n",
        "    workflow.add_node(\"email_agent\", email_agent)\n",
        "    workflow.add_node(\"question_generator_agent\", question_generator_agent)\n",
        "\n",
        "    workflow.set_entry_point(\"screening_agent\")\n",
        "    workflow.add_edge(\"screening_agent\", \"email_agent\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"email_agent\",\n",
        "        should_continue_to_interview,\n",
        "        {\n",
        "            \"question_generator_agent\": \"question_generator_agent\",\n",
        "            END: END\n",
        "        }\n",
        "    )\n",
        "    workflow.add_edge(\"question_generator_agent\", END)\n",
        "\n",
        "    return workflow.compile()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EVALUATION FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def evaluate_cv(cv_text: str, required_cv_text: str = \"\", max_retries: int = 3,\n",
        "                candidate_email: str = \"\", candidate_name: str = \"\", company_name: str = \"\"):\n",
        "    \"\"\"Evaluate a CV against job requirements.\"\"\"\n",
        "    if not cv_text or not cv_text.strip():\n",
        "        raise ValueError(\"CV text cannot be empty\")\n",
        "\n",
        "    graph = build_graph()\n",
        "\n",
        "    initial_state: IdeaEvaluationState = {\n",
        "        \"cv\": cv_text,\n",
        "        \"required_cv\": required_cv_text,\n",
        "        \"candidate_email\": candidate_email,\n",
        "        \"candidate_name\": candidate_name,\n",
        "        \"company_name\": company_name,\n",
        "    }\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            result = graph.invoke(initial_state)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                wait_time = 2 ** attempt\n",
        "                print(f\"\\nâš ï¸ Error (attempt {attempt + 1}/{max_retries}): {str(e)[:100]}\")\n",
        "                print(f\"â³ Waiting {wait_time} seconds before retry...\\n\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"\\nâŒ Failed after {max_retries} attempts\")\n",
        "                raise\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def format_screening_result(result) -> str:\n",
        "    \"\"\"Format the screening result for display.\"\"\"\n",
        "    if not result or \"screening\" not in result:\n",
        "        return \"No screening results available\"\n",
        "\n",
        "    screening = result[\"screening\"]\n",
        "    score = screening.get(\"score\", False)\n",
        "    reasoning = screening.get(\"reasoning\", \"\")\n",
        "    matched_skills = screening.get(\"matched_skills\", [])\n",
        "    missing_requirements = screening.get(\"missing_requirements\", [])\n",
        "    questions = result.get(\"questions\", {}).get(\"questions\", [])\n",
        "\n",
        "    output = [\n",
        "        \"\\n\" + \"=\"*60,\n",
        "        \"CV SCREENING RESULTS\",\n",
        "        \"=\"*60,\n",
        "        f\"\\nâœ“ MATCH: {'YES âœ…' if score else 'NO âŒ'}\",\n",
        "        f\"\\nğŸ“ Reasoning:\\n{reasoning}\",\n",
        "    ]\n",
        "\n",
        "    if matched_skills:\n",
        "        output.append(f\"\\nâœ… Matched Skills ({len(matched_skills)}):\")\n",
        "        for skill in matched_skills:\n",
        "            output.append(f\"   â€¢ {skill}\")\n",
        "\n",
        "    if missing_requirements:\n",
        "        output.append(f\"\\nâŒ Missing Requirements ({len(missing_requirements)}):\")\n",
        "        for req in missing_requirements:\n",
        "            output.append(f\"   â€¢ {req}\")\n",
        "\n",
        "    if questions:\n",
        "        output.append(f\"\\nğŸ¯ Generated Interview Questions ({len(questions)}):\")\n",
        "        for i, q in enumerate(questions[:5], 1):  # Show first 5\n",
        "            output.append(f\"   {i}. {q}\")\n",
        "        if len(questions) > 5:\n",
        "            output.append(f\"   ... and {len(questions) - 5} more questions\")\n",
        "\n",
        "    output.append(\"\\n\" + \"=\"*60)\n",
        "    return \"\\n\".join(output)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cv_text = \"\"\"\n",
        "# **Mahmoud Mohamed Omran**\n",
        "# **Machine Learning Engineer**\n",
        "\n",
        "Future City, Cairo | (+20) 1113719367 | Mahmoudomran36@gmail.com\n",
        "LinkedIn: linkedin.com/in/mahmoud-omran\n",
        "Github: github.com/Omran28\n",
        "\n",
        "## **Summary:**\n",
        "Computer Science graduate with experience developing AI solutions in computer vision, NLP, and predictive modelling.\n",
        "Proficient in PyTorch, TensorFlow, SQL, and Azure.\n",
        "\n",
        "## **Experience:**\n",
        "### **Computer Vision Intern**\n",
        "**National Telecommunication Institute (NTI)** | Jul 2025 â€“ Present\n",
        "- ML pipelines, CNNs, NLP techniques\n",
        "\n",
        "### **Data Analytics Intern**\n",
        "**EYouth**, Giza | Apr 2025 â€“ May 2025\n",
        "- Azure-based e-commerce, Random forest (98% accuracy)\n",
        "\n",
        "## **Education:**\n",
        "**Bachelor's Degree in Computer Science**\n",
        "**Ain Shams University** (2019 â€“ 2023)\n",
        "\n",
        "## **Technical Skills:**\n",
        "- Python, SQL, C++, Java\n",
        "- PyTorch, TensorFlow, Pandas, NumPy\n",
        "- Git, Flask, Django, Streamlit, Azure\n",
        "\n",
        "## **Projects:**\n",
        "- Customer Repurchase Classification (98% accuracy)\n",
        "- Thief Video Classifier (99.74% accuracy)\n",
        "\"\"\"\n",
        "\n",
        "    required_cv_text = \"\"\"\n",
        "**Job Requirements:**\n",
        "- 2+ years experience in Machine Learning\n",
        "- Strong Python skills\n",
        "- Experience with PyTorch and TensorFlow\n",
        "- Computer Vision expertise\n",
        "- Bachelor's degree in Computer Science\n",
        "- Experience with deployment tools (Docker, Streamlit)\n",
        "- Cloud platforms (AWS, Azure, GCP)\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ğŸš€ CV EVALUATION SYSTEM\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        result = evaluate_cv(\n",
        "            cv_text,\n",
        "            required_cv_text,\n",
        "            candidate_email=\"sondosahmed72@gmail.com\",\n",
        "            candidate_name=\"Sondos Ahmed\",\n",
        "            company_name=\"TechCorp AI\"\n",
        "        )\n",
        "\n",
        "        print(format_screening_result(result))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "Gl9ACuTrh_JH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2c2a69-38fe-4634-c765-107fe0abb0cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸš€ CV EVALUATION SYSTEM\n",
            "============================================================\n",
            "\n",
            "ğŸ” Starting CV Screening...\n",
            "\n",
            "ğŸ“¤ Sending prompt to LLM...\n",
            "\n",
            "ğŸ” Raw LLM response:\n",
            "Human: You are an HR recruiter. Analyze this CV against job requirements.\n",
            "\n",
            "Job Requirements:\n",
            "\n",
            "**Job Requirements:**\n",
            "- 2+ years experience in Machine Learning\n",
            "- Strong Python skills\n",
            "- Experience with PyTorch and TensorFlow\n",
            "- Computer Vision expertise\n",
            "- Bachelor's degree in Computer Science\n",
            "- Experience with deployment tools (Docker, Streamlit)\n",
            "- Cloud platforms (AWS, Azure, GCP)\n",
            "\n",
            "\n",
            "Candidate CV:\n",
            "\n",
            "# **Mahmoud Mohamed Omran**\n",
            "# **Machine Learning Engineer**\n",
            "\n",
            "Future City, Cairo | (+20) 1113719367 | M...\n",
            "\n",
            "âœ¨ Extracted JSON:\n",
            "{\"score\": true, \"reasoning\": \"Mahmoud has strong Python skills, experience with PyTorch and TensorFlow, and experience with Azure. He also has a strong understanding of computer vision and has worked on several projects.\", \"matched_skills\": [\"Python\", \"PyTorch\", \"TensorFlow\", \"Azure\"], \"missing_requirements\": [\"Computer Vision\"]}\n",
            "\n",
            "ğŸ“§ Email notification step...\n",
            "âœ… Candidate ACCEPTED - Would send acceptance email\n",
            "\n",
            "ğŸ“ Generating interview questions...\n",
            "\n",
            "ğŸ“¤ Sending prompt to LLM...\n",
            "\n",
            "ğŸ” Raw LLM response:\n",
            "Human: Generate 20 interview questions for this candidate.\n",
            "\n",
            "Job Requirements:\n",
            "\n",
            "**Job Requirements:**\n",
            "- 2+ years experience in Machine Learning\n",
            "- Strong Python skills\n",
            "- Experience with PyTorch and TensorFlow\n",
            "- Computer Vision expertise\n",
            "- Bachelor's degree in Computer Science\n",
            "- Experience with deployment tools (Docker, Streamlit)\n",
            "- Cloud platforms (AWS, Azure, GCP)\n",
            "\n",
            "\n",
            "Candidate CV:\n",
            "\n",
            "# **Mahmoud Mohamed Omran**\n",
            "# **Machine Learning Engineer**\n",
            "\n",
            "Future City, Cairo | (+20) 1113719367 | Mahmoudomran36@g...\n",
            "\n",
            "âœ¨ Extracted JSON:\n",
            "{\"score\": false, \"reasoning\": \"\", \"matched_skills\": [], \"missing_requirements\": []}\n",
            "âœ… Generated 0 questions\n",
            "\n",
            "============================================================\n",
            "CV SCREENING RESULTS\n",
            "============================================================\n",
            "\n",
            "âœ“ MATCH: YES âœ…\n",
            "\n",
            "ğŸ“ Reasoning:\n",
            "Mahmoud has strong Python skills, experience with PyTorch and TensorFlow, and experience with Azure. He also has a strong understanding of computer vision and has worked on several projects.\n",
            "\n",
            "âœ… Matched Skills (4):\n",
            "   â€¢ Python\n",
            "   â€¢ PyTorch\n",
            "   â€¢ TensorFlow\n",
            "   â€¢ Azure\n",
            "\n",
            "âŒ Missing Requirements (1):\n",
            "   â€¢ Computer Vision\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qpzoMWwBFmyl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}